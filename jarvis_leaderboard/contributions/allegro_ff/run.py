# -*- coding: utf-8 -*-
"""Train_MLFF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/Train_MLFF.ipynb
"""

# install wandb
!pip install wandb

# install nequip
!pip install nequip==0.5.5 torch==1.11

# fix colab imports
import site
site.main()

# set to allow anonymous WandB
import os
os.environ["WANDB_ANONYMOUS"] = "must"

# install allegro
!git clone --depth 1 https://github.com/mir-group/allegro.git
!pip install allegro/



# get data from mlearn
#!rm *.json
!for m in Ni Cu Mo Ge Si Li; do wget https://github.com/materialsvirtuallab/mlearn/raw/master/data/${m}/test.json; mv test.json ${m}_test.json; done;
!ls

# get data from mlearn
#!rm *.json
!for m in Ni Cu Mo Ge Si Li; do wget https://github.com/materialsvirtuallab/mlearn/raw/master/data/${m}/training.json; mv training.json ${m}_training.json; done;
!ls

pip install pymatgen

# install allegro
!git clone --depth 1 https://github.com/mir-group/allegro.git
!pip install allegro/

pip install jarvis-tools

import numpy as np
from jarvis.core.atoms import pmg_to_atoms
from jarvis.db.jsonutils import dumpjson
from jarvis.db.jsonutils import loadjson
from monty.serialization import loadfn, MontyEncoder, MontyDecoder
from ase.stress import voigt_6_to_full_3x3_stress
# Ref: https://github.com/materialsvirtuallab/mlearn
data = loadfn(
    "Si_training.json",
    cls=MontyDecoder,
)
train_structures = [d["structure"] for d in data]
train_energies = [d["outputs"]["energy"] for d in data]
train_forces = [d["outputs"]["forces"] for d in data]
train_stresses = [d["outputs"]["virial_stress"] for d in data]


data = loadfn(
    "Si_test.json",
    cls=MontyDecoder,
)
test_structures = [d["structure"] for d in data]
test_energies = [d["outputs"]["energy"] for d in data]
test_forces = [d["outputs"]["forces"] for d in data]
test_stresses = [d["outputs"]["virial_stress"] for d in data]

import os
# fix colab imports
import site
site.main()

# set to allow anonymous WandB
os.environ["WANDB_ANONYMOUS"] = "must"
os.makedirs('Si_data')

f = open("Si_data/sitraj.xyz", "w")
mem = []
count = 0
line = ""
for i, j, k, l in zip(
    train_structures, train_energies, train_forces, train_stresses
):
    info = {}
    atoms = pmg_to_atoms(i)
    #print(atoms)
    count += 1
    info["jid"] = str(count)
    info["atoms"] = atoms.to_dict()
    info["total_energy"] = j / atoms.num_atoms
    info["forces"] = k
    info["stresses"] = voigt_6_to_full_3x3_stress(l).tolist()
    mem.append(info)
    line += str(atoms.num_atoms) + "\n"
    line += (
        "Lattice="
        + '"'
        + " ".join(map(str, (atoms.lattice_mat).flatten()))
        + '"'
        + " Properties=species:S:1:pos:R:3:forces:R:3 energy="
        + str(j)
        + ' stress="'
        + " ".join(map(str, np.array(info["stresses"]).flatten()))
        + '"'
        + " free_energy="
        + str(j)
        + ' pbc="T T T"'
        + "\n"
    )
    for m, n, p in zip(atoms.elements, atoms.cart_coords, k):
        line += (
            str(m)
            + " "
            + " ".join(map(str, n))
            + " "
            + " ".join(map(str, p))
            + "\n"
        )
    # print(line)
    f.write(line)
for i, j, k, l in zip(
    test_structures, test_energies, test_forces, train_stresses
):
    info = {}
    count += 1
    info["jid"] = str(count)
    atoms = pmg_to_atoms(i)
    info["atoms"] = atoms.to_dict()
    info["total_energy"] = j / atoms.num_atoms
    info["forces"] = k
    #info["stresses"] = l
    #info["stresses"] = voigt_6_to_full_3x3_stress(l)
    info["stresses"] = voigt_6_to_full_3x3_stress(l).tolist()
    mem.append(info)
    line += str(atoms.num_atoms) + "\n"
    line += (
        "Lattice="
        + '"'
        + " ".join(map(str, (atoms.lattice_mat).flatten()))
        + '"'
        + " Properties=species:S:1:pos:R:3:forces:R:3 energy="
        + str(j)
        + ' stress="'
        #+ " ".join(map(str, np.array(l).flatten()))
        + " ".join(map(str, np.array(info["stresses"]).flatten()))
        + '"'
        + " free_energy="
        + str(j)
        + ' pbc="T T T"'
        + "\n"
    )
    for m, n, p in zip(atoms.elements, atoms.cart_coords, k):
        line += (
            str(m)
            + " "
            + " ".join(map(str, n))
            + " "
            + " ".join(map(str, p))
            + "\n"
        )
    # print(line)
    f.write(line)
for i, j, k, l in zip(
    test_structures, test_energies, test_forces, train_stresses
):
    info = {}
    count += 1
    info["jid"] = str(count)
    atoms = pmg_to_atoms(i)
    info["atoms"] = atoms.to_dict()
    info["total_energy"] = j / atoms.num_atoms
    info["forces"] = k
    #info["stresses"] = l
    #info["stresses"] = voigt_6_to_full_3x3_stress(l)
    info["stresses"] = voigt_6_to_full_3x3_stress(l).tolist()
    mem.append(info)
    line += str(atoms.num_atoms) + "\n"
    line += (
        "Lattice="
        + '"'
        + " ".join(map(str, (atoms.lattice_mat).flatten()))
        + '"'
        + " Properties=species:S:1:pos:R:3:forces:R:3 energy="
        + str(j)
        + ' stress="'
        #+ " ".join(map(str, np.array(l).flatten()))
        + " ".join(map(str, np.array(info["stresses"]).flatten()))
        + '"'
        + " free_energy="
        + str(j)
        + ' pbc="T T T"'
        + "\n"
    )
    for m, n, p in zip(atoms.elements, atoms.cart_coords, k):
        line += (
            str(m)
            + " "
            + " ".join(map(str, n))
            + " "
            + " ".join(map(str, p))
            + "\n"
        )
    # print(line)
    f.write(line)
f.close()
dumpjson(data=mem, filename="Si_data/id_prop.json")

# Commented out IPython magic to ensure Python compatibility.
# %%time
# !rm -rf ./results
# !nequip-train allegro/configs/tutorial.yaml --equivariance-test

! ls results/silicon-tutorial/si #/best_model.pth

import torch
from nequip.utils import Config
from nequip.model import model_from_config
from nequip.data import AtomicData, ASEDataset
device = "cpu"
if torch.cuda.is_available():
    device = torch.device("cuda")
config = Config.from_file("results/silicon-tutorial/si/config.yaml")

#config["train_on_keys"]=["forces", "total_energy"]
#config["model_builders"] = ["EnergyModel", "PerSpeciesRescale", "ForceOutput", "RescaleEnergyEtc"]
model = model_from_config(config, initialize=False)
d = torch.load('results/silicon-tutorial/si/best_model.pth',map_location=device)
model.load_state_dict(d)

model

from jarvis.core.atoms import Atoms
from jarvis.db.figshare import get_jid_data
atoms = Atoms.from_dict(get_jid_data(jid='JVASP-1002',dataset='dft_3d')['atoms'])
ase_atoms = atoms.ase_converter()
a = ASEDataset.from_atoms_list([ase_atoms,ase_atoms],extra_fixed_fields={"r_max": 5.0})

from nequip.data import AtomicData, Collater, dataset_from_config, register_fields, AtomicDataDict
from nequip.data.transforms import TypeMapper
# c = Collater.for_dataset(a, exclude_keys=[])
a = AtomicData.from_ase(ase_atoms,5)
data = AtomicData.to_AtomicDataDict(a)
# tm = TypeMapper(chemical_symbol_to_type={"Si": 0})
tm = TypeMapper(chemical_symbol_to_type = config['chemical_symbol_to_type'])
data = tm(data)
out = model(data)

import os
os.chdir('/content')
if not os.path.exists('jarvis_leaderboard'):
  !git clone https://github.com/usnistgov/jarvis_leaderboard.git
# os.chdir('jarvis_leaderboard')
# !pip install -e .
os.chdir('/content/jarvis_leaderboard/jarvis_leaderboard/contributions/')
os.makedirs('allegro_si')
os.chdir('allegro_si')

!wget https://figshare.com/ndownloader/files/40357663 -O mlearn.json.zip

import pandas as pd
import json,zipfile
df = pd.DataFrame(
    json.loads(
        zipfile.ZipFile("mlearn.json.zip").read(
            "mlearn.json"
        )
    )
)

!pwd

def get_allegro_forces(model=[],atoms=[],cutoff=5):
    ase_atoms = atoms.ase_converter()
    a = AtomicData.from_ase(ase_atoms,cutoff)
    data = AtomicData.to_AtomicDataDict(a)
    tm = TypeMapper(chemical_symbol_to_type = config['chemical_symbol_to_type'])
    data = tm(data)
    out = model(data)
    pen=out['total_energy'].squeeze().cpu().detach().numpy().tolist()
    num_atoms=atoms.num_atoms
    pf=out['forces'].squeeze().cpu().detach().numpy()
    return pen,pf,_

import glob
for i in glob.glob("../../benchmarks/AI/MLFF/*energy*.zip"):
    if "mlearn" in i and "Si" in i:
        fname_e = (
            "AI-MLFF-energy-"
            + i.split("/")[-1].split("_energy.json.zip")[0]
            + "-test-mae.csv"
        )
        fname_f = (
            "AI-MLFF-forces-"
            + i.split("/")[-1].split("_energy.json.zip")[0]
            + "-test-multimae.csv"
        )
        fname_s = (
            "AI-MLFF-stresses-"
            + i.split("/")[-1].split("_energy.json.zip")[0]
            + "-test-multimae.csv"
        )
        f_e = open(fname_e, "w")
        f_f = open(fname_f, "w")
        #f_s = open(fname_s, "w")

        f_e.write("id,target,prediction\n")
        f_f.write("id,prediction\n")
        #f_s.write("id,prediction\n")

        print(i)
        dat = json.loads(
            zipfile.ZipFile(i).read(i.split("/")[-1].split(".zip")[0])
        )
        print(dat["test"])
        for key, val in dat["test"].items():
            entry = df[df["jid"] == key]
            atoms = Atoms.from_dict(entry.atoms.values[0])
            # print(key,val,df[df['jid']==key],atoms)
            # energy,forces=get_alignn_forces(atoms)
            energy, forces, stress = get_allegro_forces(model=model,atoms=atoms)
            print(key, val, energy, atoms.num_atoms)
            line = key +","+ str(entry.energy.values[0])+"," + str(energy) + "\n"
            f_e.write(line)
            line = (
                key
                + ","
                + str(";".join(map(str, np.array(forces).flatten())))
                + "\n"
            )
            f_f.write(line)
            # line = (
            #     key
            #     + ","
            #     + str(";".join(map(str, np.array(stress).flatten())))
            #     + "\n"
            # )
            # f_s.write(line)
        f_e.close()
        f_f.close()
        # f_s.close()
        zname = fname_e + ".zip"
        with zipfile.ZipFile(zname, "w") as myzip:
            myzip.write(fname_e)

        zname = fname_f + ".zip"
        with zipfile.ZipFile(zname, "w") as myzip:
            myzip.write(fname_f)

        # zname = fname_s + ".zip"
        # with zipfile.ZipFile(zname, "w") as myzip:
        #     myzip.write(fname_s)

entry.energy.values[0]

!ls -altr

en_df = pd.read_csv('AI-MLFF-energy-mlearn_Si-test-mae.csv.zip')

en_df

from sklearn.metrics import mean_absolute_error
mean_absolute_error(en_df['target'],en_df['prediction'])

actual_en=[]
pred_en=[]
actual_forces=[]
pred_forces=[]

for i, j, k, l in zip(
    test_structures, test_energies, test_forces, train_stresses
):
    atoms = pmg_to_atoms(i)
    ase_atoms = atoms.ase_converter()
    a = AtomicData.from_ase(ase_atoms,5)
    data = AtomicData.to_AtomicDataDict(a)
    tm = TypeMapper(chemical_symbol_to_type = config['chemical_symbol_to_type'])
    data = tm(data)
    out = model(data)
    pen=out['total_energy'].squeeze().cpu().detach().numpy().tolist()
    print(j,pen)
    num_atoms=atoms.num_atoms
    actual_en.append(j/num_atoms)
    pred_en.append(pen/num_atoms)
    actual_forces.append(np.array(k).flatten())
    pf=out['forces'].squeeze().cpu().detach().numpy()
    pred_forces.append(pf.flatten())
    #break

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
plt.plot(actual_en,pred_en,'.')
plt.xlabel('DFT energy(eV/atom)')
plt.ylabel('FF energy(eV/atom)')

from sklearn.metrics import mean_absolute_error
mean_absolute_error(actual_en,pred_en)#energy error MAE per atom

actual_forces = np.concatenate(actual_forces)
pred_forces = np.concatenate(pred_forces)

plt.plot(actual_forces,pred_forces,'.')

mean_absolute_error(actual_forces,pred_forces)

out.keys()

out['total_energy'].squeeze().cpu().detach().numpy().tolist()

out['forces'].squeeze().cpu().detach().numpy() #.tolist()

model_parameters = filter(lambda p: p.requires_grad, model.parameters())
params = sum([np.prod(p.size()) for p in model_parameters])
params

config

